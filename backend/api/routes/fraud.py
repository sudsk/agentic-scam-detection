# backend/api/routes/fraud.py - UPDATED TO USE FRAUD DETECTION ORCHESTRATOR
"""
Fraud detection API routes - UPDATED to use FraudDetectionOrchestrator instead of fraud_detection_system
Eliminates the redundant fraud_detection_system.py and uses proper orchestration
"""

import logging
from typing import Dict, List, Optional

from fastapi import APIRouter, Depends, Query

# UPDATED: Import orchestrator instead of fraud_detection_system
from ...orchestrator.fraud_detection_orchestrator import FraudDetectionOrchestrator
from ...middleware.error_handling import handle_api_errors, validate_input, require_session_id
from ...services.mock_database import mock_db, session_service
from ..models import (
    FraudAnalysisRequest, 
    FraudAnalysisResult, 
    SuccessResponse
)
from ...utils import (
    get_current_timestamp, generate_session_id, create_success_response,
    create_error_response, calculate_percentage
)
from ...config.settings import get_settings

logger = logging.getLogger(__name__)
router = APIRouter()

# UPDATED: Create global orchestrator instance
orchestrator = FraudDetectionOrchestrator()

@router.post("/analyze", response_model=FraudAnalysisResult)
@handle_api_errors("fraud_analysis")
@validate_input(
    text={"required": True, "type": str, "min_length": 3, "max_length": 10000},
    session_id={"required": False, "type": str}
)
async def analyze_text_for_fraud(
    request: FraudAnalysisRequest,
    settings = Depends(get_settings)
):
    """Analyze text for fraud patterns using FraudDetectionOrchestrator"""
    
    # Generate session ID using centralized utility
    session_id = request.session_id or generate_session_id("fraud_analysis")
    
    # Skip analysis for agent speech in demo mode
    if request.speaker == "agent" and settings.demo_mode:
        return _create_minimal_response(session_id)
    
    try:
        # UPDATED: Use orchestrator instead of fraud_detection_agent
        logger.info(f"ðŸŽ­ REST API using Orchestrator for text analysis: {session_id}")
        
        # Use orchestrator's text analysis method
        orchestration_result = await orchestrator.orchestrate_text_analysis(
            customer_text=request.text,
            session_id=session_id,
            context={
                'speaker': request.speaker,
                'api_context': request.context,
                'source': 'rest_api'
            }
        )
        
        if not orchestration_result.get('success'):
            raise ValueError(f"Orchestration failed: {orchestration_result.get('error')}")
        
        # Extract analysis result from orchestration
        analysis_data = orchestration_result['analysis_result']
        scam_analysis = analysis_data.get('scam_analysis', {})
        
        # Create response using existing models
        response = FraudAnalysisResult(
            session_id=session_id,
            risk_score=scam_analysis.get('risk_score', 0),
            risk_level=scam_analysis.get('risk_level', 'MINIMAL'),
            scam_type=scam_analysis.get('scam_type', 'unknown'),
            confidence=scam_analysis.get('confidence', 0.0),
            detected_patterns=analysis_data.get('accumulated_patterns', {}),
            explanation=scam_analysis.get('explanation', 'Analysis completed via orchestrator'),
            recommended_action=analysis_data.get('decision_result', {}).get('decision', 'CONTINUE_NORMAL'),
            requires_escalation=scam_analysis.get('risk_score', 0) >= 80,
            analysis_timestamp=get_current_timestamp()
        )
        
        # Store session data using consolidated service
        session_data = {
            "session_id": session_id,
            "text_analyzed": request.text[:200] + "..." if len(request.text) > 200 else request.text,
            "risk_score": response.risk_score,
            "scam_type": response.scam_type,
            "speaker": request.speaker,
            "status": "analyzed",
            "orchestrator": "FraudDetectionOrchestrator",
            "agents_involved": orchestration_result.get('agents_involved', [])
        }
        session_service.create_session(session_data)
        
        logger.info(f"âœ… Orchestrator analysis completed: Risk {response.risk_score}% - {response.scam_type}")
        return response
        
    except Exception as e:
        logger.error(f"âŒ Orchestrator analysis failed: {e}")
        raise ValueError(f"Fraud analysis failed: {str(e)}")

@router.get("/patterns")
@handle_api_errors("get_patterns")
async def get_scam_patterns(settings = Depends(get_settings)):
    """Get available scam patterns from orchestrator's agents"""
    
    try:
        # UPDATED: Get patterns from orchestrator's scam detection agent
        if not orchestrator.adk_agents_available:
            raise ValueError("Orchestrator agents not available")
        
        patterns = []
        pattern_weights = settings.pattern_weights
        
        # Get patterns from orchestrator's scam detection agent
        # Note: This would need to be implemented in the agent to expose patterns
        # For now, we'll use the settings-based approach but note the orchestrator source
        
        for pattern_id, weight in pattern_weights.items():
            pattern = {
                "pattern_id": pattern_id,
                "pattern_name": pattern_id.replace('_', ' ').title(),
                "description": f"Detects {pattern_id.replace('_', ' ')} patterns in customer speech",
                "weight": weight,
                "severity": "medium",  # Default
                "source": "orchestrator_managed_agents"
            }
            patterns.append(pattern)
        
        return create_success_response(
            data=patterns,
            message="Scam patterns retrieved from Orchestrator-managed agents"
        )
        
    except Exception as e:
        logger.error(f"âŒ Error getting patterns from orchestrator: {e}")
        return create_error_response(
            error=str(e),
            code="ORCHESTRATOR_PATTERN_ERROR"
        )

@router.get("/statistics")
@handle_api_errors("fraud_statistics")
async def get_fraud_statistics(
    time_period: str = Query("24h", regex="^(1h|24h|7d|30d)$"),
    session_id: Optional[str] = Query(None)
):
    """Get fraud detection statistics using orchestrator and consolidated database"""
    
    try:
        # Get statistics from consolidated database service
        session_stats = mock_db.get_statistics("fraud_sessions")
        
        # Get orchestrator statistics
        orchestrator_status = orchestrator.get_orchestrator_status()
        
        # Calculate fraud detection metrics
        sessions, total_count = mock_db.list_records("fraud_sessions", page=1, page_size=1000)
        sessions_data = [record.data for record in sessions]
        
        # Filter by session_id if provided
        if session_id:
            sessions_data = [s for s in sessions_data if s.get('session_id') == session_id]
        
        # Calculate statistics using centralized utilities
        total_analyses = len(sessions_data)
        fraud_detected = len([s for s in sessions_data if s.get('risk_score', 0) >= 40])
        high_risk_cases = len([s for s in sessions_data if s.get('risk_score', 0) >= 80])
        orchestrator_sessions = len([s for s in sessions_data if s.get('orchestrator') == 'FraudDetectionOrchestrator'])
        
        # Get scam type breakdown
        scam_types = {}
        for session in sessions_data:
            scam_type = session.get('scam_type', 'unknown')
            if scam_type != 'none' and scam_type != 'unknown':
                scam_types[scam_type] = scam_types.get(scam_type, 0) + 1
        
        # Calculate rates using centralized utilities
        fraud_detection_rate = calculate_percentage(fraud_detected, total_analyses)
        high_risk_rate = calculate_percentage(high_risk_cases, total_analyses)
        orchestrator_usage_rate = calculate_percentage(orchestrator_sessions, total_analyses)
        
        # Get average risk score
        risk_scores = [s.get('risk_score', 0) for s in sessions_data if s.get('risk_score')]
        average_risk_score = sum(risk_scores) / len(risk_scores) if risk_scores else 0
        
        statistics = {
            "time_period": time_period,
            "total_analyses": total_analyses,
            "fraud_detected": fraud_detected,
            "high_risk_cases": high_risk_cases,
            "fraud_detection_rate": fraud_detection_rate,
            "high_risk_rate": high_risk_rate,
            "average_risk_score": round(average_risk_score, 2),
            "scam_types": scam_types,
            "orchestrator_info": {
                "active_sessions": orchestrator_status.get('active_sessions', 0),
                "agents_available": orchestrator_status.get('agents_available', False),
                "agents_managed": orchestrator_status.get('agents_managed', []),
                "usage_rate": orchestrator_usage_rate,
                "total_orchestrated_sessions": orchestrator_sessions
            },
            "system_architecture": {
                "orchestrator": "FraudDetectionOrchestrator",
                "data_source": "Consolidated MockDatabase service",
                "utilities_used": "Centralized calculation functions",
                "configuration": "Centralized risk thresholds from settings.py",
                "fraud_detection_system_eliminated": True
            }
        }
        
        return create_success_response(
            data=statistics,
            message="Fraud statistics retrieved using FraudDetectionOrchestrator"
        )
        
    except Exception as e:
        logger.error(f"âŒ Error getting statistics from orchestrator: {e}")
        return create_error_response(
            error=str(e),
            code="ORCHESTRATOR_STATISTICS_ERROR"
        )

@router.post("/analyze-batch")
@handle_api_errors("batch_fraud_analysis")
async def analyze_batch_for_fraud(
    requests: List[FraudAnalysisRequest],
    settings = Depends(get_settings)
):
    """Batch analyze multiple texts using FraudDetectionOrchestrator"""
    
    if len(requests) > 50:  # Reasonable batch limit
        raise ValueError("Batch size too large. Maximum 50 requests per batch.")
    
    try:
        logger.info(f"ðŸŽ­ REST API batch analysis using Orchestrator: {len(requests)} requests")
        
        batch_results = []
        batch_session_id = generate_session_id("batch_analysis")
        
        for i, request in enumerate(requests):
            try:
                # Generate individual session ID for each request
                individual_session_id = f"{batch_session_id}_item_{i+1}"
                
                # Skip agent speech in demo mode
                if request.speaker == "agent" and settings.demo_mode:
                    result = _create_minimal_response(individual_session_id)
                else:
                    # Use orchestrator for analysis
                    orchestration_result = await orchestrator.orchestrate_text_analysis(
                        customer_text=request.text,
                        session_id=individual_session_id,
                        context={
                            'speaker': request.speaker,
                            'api_context': request.context,
                            'source': 'rest_api_batch',
                            'batch_id': batch_session_id,
                            'item_index': i
                        }
                    )
                    
                    if orchestration_result.get('success'):
                        analysis_data = orchestration_result['analysis_result']
                        scam_analysis = analysis_data.get('scam_analysis', {})
                        
                        result = FraudAnalysisResult(
                            session_id=individual_session_id,
                            risk_score=scam_analysis.get('risk_score', 0),
                            risk_level=scam_analysis.get('risk_level', 'MINIMAL'),
                            scam_type=scam_analysis.get('scam_type', 'unknown'),
                            confidence=scam_analysis.get('confidence', 0.0),
                            detected_patterns=analysis_data.get('accumulated_patterns', {}),
                            explanation=scam_analysis.get('explanation', 'Batch analysis via orchestrator'),
                            recommended_action=analysis_data.get('decision_result', {}).get('decision', 'CONTINUE_NORMAL'),
                            requires_escalation=scam_analysis.get('risk_score', 0) >= 80,
                            analysis_timestamp=get_current_timestamp()
                        )
                    else:
                        # Create error result
                        result = FraudAnalysisResult(
                            session_id=individual_session_id,
                            risk_score=0.0,
                            risk_level="MINIMAL",
                            scam_type="unknown",
                            confidence=0.0,
                            detected_patterns={},
                            explanation=f"Orchestration failed: {orchestration_result.get('error')}",
                            recommended_action="REVIEW_REQUIRED",
                            requires_escalation=False,
                            analysis_timestamp=get_current_timestamp()
                        )
                
                batch_results.append(result)
                
            except Exception as e:
                logger.error(f"âŒ Batch item {i+1} failed: {e}")
                # Create error result for failed item
                error_result = FraudAnalysisResult(
                    session_id=f"{batch_session_id}_item_{i+1}",
                    risk_score=0.0,
                    risk_level="MINIMAL",
                    scam_type="unknown",
                    confidence=0.0,
                    detected_patterns={},
                    explanation=f"Analysis failed: {str(e)}",
                    recommended_action="REVIEW_REQUIRED",
                    requires_escalation=False,
                    analysis_timestamp=get_current_timestamp()
                )
                batch_results.append(error_result)
        
        # Calculate batch statistics
        total_items = len(batch_results)
        high_risk_items = len([r for r in batch_results if r.risk_score >= 80])
        medium_risk_items = len([r for r in batch_results if 40 <= r.risk_score < 80])
        average_risk = sum(r.risk_score for r in batch_results) / total_items if total_items > 0 else 0
        
        batch_summary = {
            "batch_session_id": batch_session_id,
            "total_items": total_items,
            "high_risk_items": high_risk_items,
            "medium_risk_items": medium_risk_items,
            "low_risk_items": total_items - high_risk_items - medium_risk_items,
            "average_risk_score": round(average_risk, 2),
            "requires_escalation": high_risk_items > 0,
            "orchestrator": "FraudDetectionOrchestrator",
            "processing_timestamp": get_current_timestamp()
        }
        
        return create_success_response(
            data={
                "batch_summary": batch_summary,
                "results": batch_results
            },
            message=f"Batch analysis completed via FraudDetectionOrchestrator: {total_items} items processed"
        )
        
    except Exception as e:
        logger.error(f"âŒ Batch analysis failed: {e}")
        return create_error_response(
            error=str(e),
            code="ORCHESTRATOR_BATCH_ERROR"
        )

@router.get("/orchestrator/status")
@handle_api_errors("orchestrator_status")
async def get_orchestrator_status():
    """Get FraudDetectionOrchestrator status and capabilities"""
    
    try:
        status = orchestrator.get_orchestrator_status()
        
        return create_success_response(
            data=status,
            message="FraudDetectionOrchestrator status retrieved"
        )
        
    except Exception as e:
        logger.error(f"âŒ Error getting orchestrator status: {e}")
        return create_error_response(
            error=str(e),
            code="ORCHESTRATOR_STATUS_ERROR"
        )

@router.get("/orchestrator/sessions/{session_id}")
@handle_api_errors("get_orchestrator_session")
async def get_orchestrator_session_data(session_id: str):
    """Get detailed session data from FraudDetectionOrchestrator"""
    
    try:
        session_data = orchestrator.get_session_data(session_id)
        
        if not session_data:
            return create_error_response(
                error=f"Session {session_id} not found in orchestrator",
                code="SESSION_NOT_FOUND"
            )
        
        return create_success_response(
            data={
                "session_id": session_id,
                "orchestrator": "FraudDetectionOrchestrator",
                **session_data
            },
            message="Session data retrieved from orchestrator"
        )
        
    except Exception as e:
        logger.error(f"âŒ Error getting session data: {e}")
        return create_error_response(
            error=str(e),
            code="ORCHESTRATOR_SESSION_ERROR"
        )

# ===== HELPER FUNCTIONS =====

def _create_minimal_response(session_id: str) -> FraudAnalysisResult:
    """Create minimal response for agent speech using existing models"""
    return FraudAnalysisResult(
        session_id=session_id,
        risk_score=0.0,
        risk_level="MINIMAL",
        scam_type="none",
        confidence=0.1,
        detected_patterns={},
        explanation="Agent speech - no analysis performed",
        recommended_action="CONTINUE_NORMAL_PROCESSING",
        requires_escalation=False,
        analysis_timestamp=get_current_timestamp()
    )
